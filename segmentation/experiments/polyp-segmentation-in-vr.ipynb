{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook I will be develiping a segmentation model for semantic segmentation of polyps. Then I will try to transfer the domen of images to VR environment and compare results.","metadata":{}},{"cell_type":"code","source":"import os, cv2\nimport numpy as np\nimport pandas as pd\nimport random, tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport albumentations as album","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-06-24T06:27:02.694127Z","iopub.execute_input":"2022-06-24T06:27:02.694484Z","iopub.status.idle":"2022-06-24T06:27:02.792347Z","shell.execute_reply.started":"2022-06-24T06:27:02.694452Z","shell.execute_reply":"2022-06-24T06:27:02.791602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I am using segmentation-models-pytorch for experiments\n!pip install -q -U segmentation-models-pytorch albumentations\nimport segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:27:03.153604Z","iopub.execute_input":"2022-06-24T06:27:03.153973Z","iopub.status.idle":"2022-06-24T06:27:22.459071Z","shell.execute_reply.started":"2022-06-24T06:27:03.15394Z","shell.execute_reply":"2022-06-24T06:27:22.457986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '../input/cvcclinicdb'\n\n# Pipeline to collect paths\nmetadata_df = pd.read_csv(os.path.join(DATA_DIR, 'metadata.csv'))\nmetadata_df = metadata_df[['frame_id', 'png_image_path', 'png_mask_path']]\nmetadata_df['png_image_path'] = metadata_df['png_image_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\nmetadata_df['png_mask_path'] = metadata_df['png_mask_path'].apply(lambda img_pth: os.path.join(DATA_DIR, img_pth))\n\n\nmetadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n\n# here train-test split is simple\nvalid_df = metadata_df.sample(frac=0.2, random_state=42)\ntrain_df = metadata_df.drop(valid_df.index)\nlen(train_df), len(valid_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:27:22.46103Z","iopub.execute_input":"2022-06-24T06:27:22.461361Z","iopub.status.idle":"2022-06-24T06:27:22.507345Z","shell.execute_reply.started":"2022-06-24T06:27:22.461331Z","shell.execute_reply":"2022-06-24T06:27:22.506556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_dict = pd.read_csv(os.path.join(DATA_DIR, 'class_dict.csv'))\nclass_names = class_dict['class_names'].tolist()\nclass_rgb_values = class_dict[['r','g','b']].values.tolist()\n\nprint('All dataset classes and their corresponding RGB values in labels:')\nprint('Class Names: ', *class_names)\nprint('Class RGB values: ', *class_rgb_values)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:27:22.508844Z","iopub.execute_input":"2022-06-24T06:27:22.509389Z","iopub.status.idle":"2022-06-24T06:27:22.538058Z","shell.execute_reply.started":"2022-06-24T06:27:22.509344Z","shell.execute_reply":"2022-06-24T06:27:22.537312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A model to process original images","metadata":{}},{"cell_type":"code","source":"## Retrieved from Polyp Segmentation in Colonoscopy Frames [DeepLab], https://www.kaggle.com/code/balraj98/polyp-segmentation-in-colonoscopy-frames-deeplab\n\ndef visualize(**images):\n    \"\"\"\n    Plot images in one row\n    \"\"\"\n    n_images = len(images)\n    plt.figure(figsize=(20,8))\n    for idx, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n_images, idx + 1)\n        plt.xticks([]); \n        plt.yticks([])\n        # get title from the parameter names\n        plt.title(name.replace('_',' ').title(), fontsize=20)\n        plt.imshow(image)\n    plt.show()\n\n# Perform one hot encoding on label\ndef one_hot_encode(label, label_values):\n    \"\"\"\n    Convert a segmentation image label array to one-hot format\n    by replacing each pixel value with a vector of length num_classes\n    # Arguments\n        label: The 2D array segmentation image label\n        label_values\n        \n    # Returns\n        A 2D array with the same width and hieght as the input, but\n        with a depth size of num_classes\n    \"\"\"\n    semantic_map = []\n    for colour in label_values:\n        equality = np.equal(label, colour)\n        class_map = np.all(equality, axis = -1)\n        semantic_map.append(class_map)\n    semantic_map = np.stack(semantic_map, axis=-1)\n\n    return semantic_map\n    \n# Perform reverse one-hot-encoding on labels / preds\ndef reverse_one_hot(image):\n    \"\"\"\n    Transform a 2D array in one-hot format (depth is num_classes),\n    to a 2D array with only 1 channel, where each pixel value is\n    the classified class key.\n    # Arguments\n        image: The one-hot format image \n        \n    # Returns\n        A 2D array with the same width and hieght as the input, but\n        with a depth size of 1, where each pixel value is the classified \n        class key.\n    \"\"\"\n    x = np.argmax(image, axis = -1)\n    return x\n\n# Perform colour coding on the reverse-one-hot outputs\ndef colour_code_segmentation(image, label_values):\n    \"\"\"\n    Given a 1-channel array of class keys, colour code the segmentation results.\n    # Arguments\n        image: single channel array where each value represents the class key.\n        label_values\n\n    # Returns\n        Colour coded image for segmentation visualization\n    \"\"\"\n    colour_codes = np.array(label_values)\n    x = colour_codes[image.astype(int)]\n\n    return x\n\n\n\nclass EndoscopyDataset(torch.utils.data.Dataset):\n\n    \"\"\"CVC-ClinicDB Endoscopic Colonoscopy Dataset. Read images, apply augmentation and preprocessing transformations.\n    \n    Args:\n        df (str): DataFrame containing images / labels paths\n        class_rgb_values (list): RGB values of select classes to extract from segmentation mask\n        augmentation (albumentations.Compose): data transfromation pipeline \n            (e.g. flip, scale, etc.)\n        preprocessing (albumentations.Compose): data preprocessing \n            (e.g. noralization, shape manipulation, etc.)\n    \n    \"\"\"\n    def __init__(\n            self, \n            df,\n            class_rgb_values=None, \n            augmentation=None, \n            preprocessing=None,\n            distortion=False,\n    ):\n        self.image_paths = df['png_image_path'].tolist()\n        self.mask_paths = df['png_mask_path'].tolist()\n        \n        self.class_rgb_values = class_rgb_values\n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n        self.distortion = distortion\n    \n    def __getitem__(self, i):\n        \n        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n        \n        mask = one_hot_encode(mask, self.class_rgb_values).astype('float')\n        # I have added an option to add distortion\n        if self.distortion:\n            image = album.augmentations.functional.optical_distortion(image, k=4, dx=0, dy=0, interpolation=1, border_mode=0, value=None)\n            mask = album.augmentations.functional.optical_distortion(mask, k=4, dx=0, dy=0, interpolation=1, border_mode=0, value=None)\n            \n        if self.augmentation:\n            sample = self.augmentation(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n        \n        if self.preprocessing:\n            sample = self.preprocessing(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n        \n        return image, mask\n        \n    def __len__(self):\n        return len(self.image_paths)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:04:03.296546Z","iopub.execute_input":"2022-06-24T07:04:03.296905Z","iopub.status.idle":"2022-06-24T07:04:03.322801Z","shell.execute_reply.started":"2022-06-24T07:04:03.296869Z","shell.execute_reply":"2022-06-24T07:04:03.32174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select_classes = ['background', 'polyp']\n\nselect_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\nselect_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]\n\ndataset = EndoscopyDataset(train_df, class_rgb_values=select_class_rgb_values)\nrandom_idx = random.randint(0, len(dataset)-1)\nimage, mask = dataset[2]\n\nvisualize(\n    original_image = image,\n    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n    one_hot_encoded_mask = reverse_one_hot(mask)\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:27:22.573791Z","iopub.execute_input":"2022-06-24T06:27:22.574308Z","iopub.status.idle":"2022-06-24T06:27:22.863479Z","shell.execute_reply.started":"2022-06-24T06:27:22.574269Z","shell.execute_reply":"2022-06-24T06:27:22.862545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## the number of images is low, so I will use some augmentations\n\ndef get_training_augmentation():\n    return album.Compose( [\n        album.HorizontalFlip(p=0.5),\n         album.Rotate(limit=45, p=0.5),\n         album.RandomBrightnessContrast(p=0.2),\n    ])\n\n\ndef get_validation_augmentation():\n    return album.Compose( [\n        # padding to make height and width multiples of 32\n        album.PadIfNeeded(min_height=288, min_width=384, always_apply=True, border_mode=0),\n    ])\n\n\ndef to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1).astype('float32')\n\n\ndef get_preprocessing(preprocessing_fn=None):\n    \"\"\"Construct preprocessing transform    \n    Args:\n        preprocessing_fn (callable): data normalization function \n            (can be specific for each pretrained neural network)\n    Return:\n        transform: albumentations.Compose\n    \"\"\"   \n    _transform = []\n    if preprocessing_fn:\n        _transform.append(album.Lambda(image=preprocessing_fn))\n    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n        \n    return album.Compose(_transform)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:27:22.864691Z","iopub.execute_input":"2022-06-24T06:27:22.865013Z","iopub.status.idle":"2022-06-24T06:27:22.874944Z","shell.execute_reply.started":"2022-06-24T06:27:22.864981Z","shell.execute_reply":"2022-06-24T06:27:22.874063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualize Augmented Images & Masks","metadata":{}},{"cell_type":"code","source":"augmented_dataset = EndoscopyDataset(\n    train_df, \n    augmentation=get_training_augmentation(),\n    class_rgb_values=select_class_rgb_values,\n)\n\nrandom_idx = random.randint(0, len(augmented_dataset)-1)\n\nfor idx in range(3):\n    image, mask = augmented_dataset[idx]\n    visualize(\n        original_image = image,\n        ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n        one_hot_encoded_mask = reverse_one_hot(mask)\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:27:22.876302Z","iopub.execute_input":"2022-06-24T06:27:22.876828Z","iopub.status.idle":"2022-06-24T06:27:23.531369Z","shell.execute_reply.started":"2022-06-24T06:27:22.876792Z","shell.execute_reply":"2022-06-24T06:27:23.530484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Definition","metadata":{}},{"cell_type":"code","source":"ENCODER = 'resnet50'\nENCODER_WEIGHTS = 'imagenet'\nCLASSES = select_classes\nACTIVATION = 'sigmoid' \n\nmodel = smp.DeepLabV3Plus(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    classes=2, \n    activation=ACTIVATION,\n)\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:27.565928Z","iopub.execute_input":"2022-06-24T06:41:27.566328Z","iopub.status.idle":"2022-06-24T06:41:28.751624Z","shell.execute_reply.started":"2022-06-24T06:41:27.566294Z","shell.execute_reply":"2022-06-24T06:41:28.750708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.0003)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:31.895228Z","iopub.execute_input":"2022-06-24T06:41:31.895557Z","iopub.status.idle":"2022-06-24T06:41:31.901641Z","shell.execute_reply.started":"2022-06-24T06:41:31.895527Z","shell.execute_reply":"2022-06-24T06:41:31.900762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Get Train / Val DataLoaders","metadata":{}},{"cell_type":"code","source":"# Get train and val dataset instances\ntrain_dataset = EndoscopyDataset(\n    train_df, \n    augmentation=get_training_augmentation(),\n    preprocessing=get_preprocessing(preprocessing_fn),\n    class_rgb_values=select_class_rgb_values,\n)\n\nvalid_dataset = EndoscopyDataset(\n    valid_df, \n    augmentation=get_validation_augmentation(), \n    preprocessing=get_preprocessing(preprocessing_fn),\n    class_rgb_values=select_class_rgb_values,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:32.418773Z","iopub.execute_input":"2022-06-24T06:41:32.419112Z","iopub.status.idle":"2022-06-24T06:41:32.426273Z","shell.execute_reply.started":"2022-06-24T06:41:32.419081Z","shell.execute_reply":"2022-06-24T06:41:32.424969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaders = {\n    \"train\": DataLoader(\n        train_dataset,\n        batch_size=16,\n        shuffle=True,\n        num_workers=4,\n        drop_last=True,\n    ),\n    \"valid\": DataLoader(\n        valid_dataset,\n        batch_size=16,\n        shuffle=False,\n        num_workers=4,\n        drop_last=True,\n    )\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:33.11747Z","iopub.execute_input":"2022-06-24T06:41:33.117855Z","iopub.status.idle":"2022-06-24T06:41:33.123721Z","shell.execute_reply.started":"2022-06-24T06:41:33.117821Z","shell.execute_reply":"2022-06-24T06:41:33.122697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train with catalyst","metadata":{}},{"cell_type":"code","source":"import catalyst\nfrom catalyst import dl\nfrom catalyst.utils import metrics, imread, set_global_seed","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:34.005158Z","iopub.execute_input":"2022-06-24T06:41:34.005481Z","iopub.status.idle":"2022-06-24T06:41:34.010001Z","shell.execute_reply.started":"2022-06-24T06:41:34.00545Z","shell.execute_reply":"2022-06-24T06:41:34.008847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catalyst.contrib.nn import DiceLoss, IoULoss\nfrom catalyst.dl.runner import SupervisedRunner\nfrom torch.nn.functional import interpolate\n\n\nclass SegmentationRunner(SupervisedRunner):\n    def predict_batch(self, batch):\n        prediction = {\"filename\": batch[\"filename\"]}\n        masks = self.model(batch[self.input_key].to(self.device))\n        image_size = list(zip(*batch[\"image size\"]))\n        prediction[\"mask\"] = [\n            interpolate(mask.unsqueeze(0), image_size).squeeze(0)\n            for mask, image_size in zip(masks, image_size)\n        ]\n        return prediction","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:34.376416Z","iopub.execute_input":"2022-06-24T06:41:34.376777Z","iopub.status.idle":"2022-06-24T06:41:34.38511Z","shell.execute_reply.started":"2022-06-24T06:41:34.376737Z","shell.execute_reply":"2022-06-24T06:41:34.384019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = {\n    \"dice\": DiceLoss(),\n    \"iou\": IoULoss(),\n    \"bce\": nn.BCEWithLogitsLoss()\n}\n\nrunner = SegmentationRunner(input_key=\"image\", input_target_key=\"mask\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:34.894478Z","iopub.execute_input":"2022-06-24T06:41:34.894828Z","iopub.status.idle":"2022-06-24T06:41:34.900721Z","shell.execute_reply.started":"2022-06-24T06:41:34.894794Z","shell.execute_reply":"2022-06-24T06:41:34.899688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    dl.CriterionCallback(\n        input_key=\"mask\", prefix=\"loss_dice\", criterion_key=\"dice\"\n    ),\n    dl.CriterionCallback(\n        input_key=\"mask\", prefix=\"loss_iou\", criterion_key=\"iou\"\n    ),\n    dl.CriterionCallback(\n        input_key=\"mask\", prefix=\"loss_bce\", criterion_key=\"bce\"\n    ),\n    dl.MetricAggregationCallback(\n        prefix=\"loss\",\n        mode=\"weighted_sum\",\n        metrics={\"loss_dice\": 1.0, \"loss_iou\": 1.0, \"loss_bce\": 0.8},\n    ),\n    dl.DiceCallback(input_key=\"mask\"),\n    dl.IouCallback(input_key=\"mask\"),\n]","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:35.233471Z","iopub.execute_input":"2022-06-24T06:41:35.233814Z","iopub.status.idle":"2022-06-24T06:41:35.241273Z","shell.execute_reply.started":"2022-06-24T06:41:35.233781Z","shell.execute_reply":"2022-06-24T06:41:35.240128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:35.920972Z","iopub.execute_input":"2022-06-24T06:41:35.921295Z","iopub.status.idle":"2022-06-24T06:41:35.925531Z","shell.execute_reply.started":"2022-06-24T06:41:35.921263Z","shell.execute_reply":"2022-06-24T06:41:35.924504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For this experiment I was usint catalyst as a framework\nrunner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    loaders=loaders,\n    callbacks=callbacks,\n    logdir=Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n    num_epochs=25,\n    main_metric=\"iou\", \n    minimize_metric=False,\n    verbose=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:41:36.39469Z","iopub.execute_input":"2022-06-24T06:41:36.395023Z","iopub.status.idle":"2022-06-24T06:54:30.158781Z","shell.execute_reply.started":"2022-06-24T06:41:36.39499Z","shell.execute_reply":"2022-06-24T06:54:30.157802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction on Test Data","metadata":{}},{"cell_type":"code","source":"# load best saved model checkpoint from the current run\nbest_model = runner.model","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:54:30.160868Z","iopub.execute_input":"2022-06-24T06:54:30.161134Z","iopub.status.idle":"2022-06-24T06:54:30.165157Z","shell.execute_reply.started":"2022-06-24T06:54:30.161104Z","shell.execute_reply":"2022-06-24T06:54:30.164306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create test dataloader to be used with UNet model (with preprocessing operation: to_tensor(...))\ntest_dataset = EndoscopyDataset(\n    valid_df, \n    augmentation=get_validation_augmentation(), \n    preprocessing=get_preprocessing(preprocessing_fn),\n    class_rgb_values=select_class_rgb_values,\n)\n\ntest_dataloader = DataLoader(test_dataset)\n\n# test dataset for visualization (without preprocessing augmentations & transformations)\ntest_dataset_vis = EndoscopyDataset(\n    valid_df,\n    class_rgb_values=select_class_rgb_values,\n)\n\n# get a random test image/mask index\nrandom_idx = random.randint(0, len(test_dataset_vis)-1)\nimage, mask = test_dataset_vis[random_idx]\n\nvisualize(\n    original_image = image,\n    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n    one_hot_encoded_mask = reverse_one_hot(mask)\n)\n\n# Notice the images / masks are 1536*1536 because of 18px padding on all sides. \n# This is to ensure the input image dimensions to UNet model are a multiple of 2 (to account for pooling & transpose conv. operations).","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:54:30.166634Z","iopub.execute_input":"2022-06-24T06:54:30.167163Z","iopub.status.idle":"2022-06-24T06:54:30.405872Z","shell.execute_reply.started":"2022-06-24T06:54:30.167107Z","shell.execute_reply":"2022-06-24T06:54:30.405031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Center crop padded image / mask to original image dims \ndef crop_image(image, true_dimensions):\n    return album.CenterCrop(p=1, height=true_dimensions[0], width=true_dimensions[1])(image=image)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:54:30.407258Z","iopub.execute_input":"2022-06-24T06:54:30.40784Z","iopub.status.idle":"2022-06-24T06:54:30.413988Z","shell.execute_reply.started":"2022-06-24T06:54:30.407802Z","shell.execute_reply":"2022-06-24T06:54:30.41279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save predictions\nsample_preds_folder = 'sample_predictions/'\nif not os.path.exists(sample_preds_folder):\n    os.makedirs(sample_preds_folder)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:54:30.417297Z","iopub.execute_input":"2022-06-24T06:54:30.417863Z","iopub.status.idle":"2022-06-24T06:54:30.423607Z","shell.execute_reply.started":"2022-06-24T06:54:30.417731Z","shell.execute_reply":"2022-06-24T06:54:30.422532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:54:30.425934Z","iopub.execute_input":"2022-06-24T06:54:30.426314Z","iopub.status.idle":"2022-06-24T06:54:30.432371Z","shell.execute_reply.started":"2022-06-24T06:54:30.426277Z","shell.execute_reply":"2022-06-24T06:54:30.430609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx in range(len(test_dataset)):\n\n    image, gt_mask = test_dataset[idx]\n    image_vis = test_dataset_vis[idx][0].astype('uint8')\n    true_dimensions = image_vis.shape\n    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n    # Predict test image\n    pred_mask = best_model(x_tensor)\n    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n    # Convert pred_mask from `CHW` f$ormat to `HWC` format\n    pred_mask = np.transpose(pred_mask,(1,2,0))\n    # Get prediction channel corresponding to foreground\n    pred_polyp_heatmap = crop_image(pred_mask[:,:,select_classes.index('polyp')], true_dimensions)['image']\n    pred_mask = crop_image(colour_code_segmentation(reverse_one_hot(pred_mask), select_class_rgb_values), true_dimensions)['image']\n    # Convert gt_mask from `CHW` format to `HWC` format\n    gt_mask = np.transpose(gt_mask,(1,2,0))\n    gt_mask = crop_image(colour_code_segmentation(reverse_one_hot(gt_mask), select_class_rgb_values), true_dimensions)['image']\n    cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])\n    \n    visualize(\n        original_image = image_vis,\n        ground_truth_mask = gt_mask,\n        predicted_mask = pred_mask,\n        pred_polyp_heatmap = pred_polyp_heatmap\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:54:30.43357Z","iopub.execute_input":"2022-06-24T06:54:30.433919Z","iopub.status.idle":"2022-06-24T06:55:07.301093Z","shell.execute_reply.started":"2022-06-24T06:54:30.433883Z","shell.execute_reply":"2022-06-24T06:55:07.299667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation on Test Dataset","metadata":{}},{"cell_type":"code","source":"test_epoch = smp.utils.train.ValidEpoch(\n    model,\n    loss=smp.utils.losses.DiceLoss(), \n    metrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n], \n    device=DEVICE,\n    verbose=True,\n)\n\nvalid_logs = test_epoch.run(test_dataloader)\nprint(\"Evaluation on Test Data: \")\nprint(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\nprint(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T06:55:07.302394Z","iopub.execute_input":"2022-06-24T06:55:07.302773Z","iopub.status.idle":"2022-06-24T06:55:11.423119Z","shell.execute_reply.started":"2022-06-24T06:55:07.302745Z","shell.execute_reply":"2022-06-24T06:55:11.42213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A model to process distorted images\n\nthis part of notebook is roughtle the same as the priveous one","metadata":{}},{"cell_type":"code","source":"augmented_dataset = EndoscopyDataset(\n    train_df, \n    augmentation=get_training_augmentation(),\n    class_rgb_values=select_class_rgb_values,\n    distortion=True,\n)\n\nrandom_idx = random.randint(0, len(augmented_dataset)-1)\n\nfor idx in range(3):\n    image, mask = augmented_dataset[idx]\n    visualize(\n        original_image = image,\n        ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n        one_hot_encoded_mask = reverse_one_hot(mask)\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:10:45.364849Z","iopub.execute_input":"2022-06-24T07:10:45.365175Z","iopub.status.idle":"2022-06-24T07:10:45.980989Z","shell.execute_reply.started":"2022-06-24T07:10:45.365145Z","shell.execute_reply":"2022-06-24T07:10:45.979884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get train and val dataset instances\ntrain_dataset = EndoscopyDataset(\n    train_df, \n    augmentation=get_training_augmentation(),\n    preprocessing=get_preprocessing(preprocessing_fn),\n    class_rgb_values=select_class_rgb_values,\n    distortion=True,\n\n\n)\n\nvalid_dataset = EndoscopyDataset(\n    valid_df, \n    augmentation=get_validation_augmentation(), \n    preprocessing=get_preprocessing(preprocessing_fn),\n    class_rgb_values=select_class_rgb_values,\n    distortion=True,\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:10:46.346639Z","iopub.execute_input":"2022-06-24T07:10:46.347005Z","iopub.status.idle":"2022-06-24T07:10:46.353461Z","shell.execute_reply.started":"2022-06-24T07:10:46.346971Z","shell.execute_reply":"2022-06-24T07:10:46.352629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaders = {\n    \"train\": DataLoader(\n        train_dataset,\n        batch_size=16,\n        shuffle=True,\n        num_workers=4,\n        drop_last=True,\n    ),\n    \"valid\": DataLoader(\n        valid_dataset,\n        batch_size=16,\n        shuffle=False,\n        num_workers=4,\n        drop_last=True,\n    )\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:11:04.031158Z","iopub.execute_input":"2022-06-24T07:11:04.031483Z","iopub.status.idle":"2022-06-24T07:11:04.037568Z","shell.execute_reply.started":"2022-06-24T07:11:04.031454Z","shell.execute_reply":"2022-06-24T07:11:04.036366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = smp.DeepLabV3Plus(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    classes=2, \n    activation=ACTIVATION,\n)\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:11:04.694157Z","iopub.execute_input":"2022-06-24T07:11:04.694492Z","iopub.status.idle":"2022-06-24T07:11:05.388921Z","shell.execute_reply.started":"2022-06-24T07:11:04.694459Z","shell.execute_reply":"2022-06-24T07:11:05.388123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.0003)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:11:05.912303Z","iopub.execute_input":"2022-06-24T07:11:05.912643Z","iopub.status.idle":"2022-06-24T07:11:05.918734Z","shell.execute_reply.started":"2022-06-24T07:11:05.91261Z","shell.execute_reply":"2022-06-24T07:11:05.917498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"runner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    loaders=loaders,\n    callbacks=callbacks,\n    logdir=Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n    num_epochs=10,\n    main_metric=\"iou\", \n    minimize_metric=False,\n    verbose=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:11:06.677667Z","iopub.execute_input":"2022-06-24T07:11:06.678057Z","iopub.status.idle":"2022-06-24T07:16:22.626964Z","shell.execute_reply.started":"2022-06-24T07:11:06.678019Z","shell.execute_reply":"2022-06-24T07:16:22.625842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = runner.model\n\ntest_dataset = EndoscopyDataset(\n    valid_df, \n    augmentation=get_validation_augmentation(), \n    preprocessing=get_preprocessing(preprocessing_fn),\n    class_rgb_values=select_class_rgb_values,\n    distortion=True,\n\n\n)\n\ntest_dataloader = DataLoader(test_dataset)\n\n# test dataset for visualization (without preprocessing augmentations & transformations)\ntest_dataset_vis = EndoscopyDataset(\n    valid_df,\n    class_rgb_values=select_class_rgb_values,\n    distortion=True,\n\n)\n\n# get a random test image/mask index\nrandom_idx = random.randint(0, len(test_dataset_vis)-1)\nimage, mask = test_dataset_vis[random_idx]\n\nvisualize(\n    original_image = image,\n    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask), select_class_rgb_values),\n    one_hot_encoded_mask = reverse_one_hot(mask)\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:16:22.632851Z","iopub.execute_input":"2022-06-24T07:16:22.635375Z","iopub.status.idle":"2022-06-24T07:16:22.899525Z","shell.execute_reply.started":"2022-06-24T07:16:22.635321Z","shell.execute_reply":"2022-06-24T07:16:22.898533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx in range(len(test_dataset)):\n\n    image, gt_mask = test_dataset[idx]\n    image_vis = test_dataset_vis[idx][0].astype('uint8')\n    true_dimensions = image_vis.shape\n    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n    # Predict test image\n    pred_mask = best_model(x_tensor)\n    pred_mask = pred_mask.detach().squeeze().cpu().numpy()\n    # Convert pred_mask from `CHW` format to `HWC` format\n    pred_mask = np.transpose(pred_mask,(1,2,0))\n    # Get prediction channel corresponding to foreground\n    pred_polyp_heatmap = crop_image(pred_mask[:,:,select_classes.index('polyp')], true_dimensions)['image']\n    pred_mask = crop_image(colour_code_segmentation(reverse_one_hot(pred_mask), select_class_rgb_values), true_dimensions)['image']\n    # Convert gt_mask from `CHW` format to `HWC` format\n    gt_mask = np.transpose(gt_mask,(1,2,0))\n    gt_mask = crop_image(colour_code_segmentation(reverse_one_hot(gt_mask), select_class_rgb_values), true_dimensions)['image']\n    cv2.imwrite(os.path.join(sample_preds_folder, f\"sample_pred_{idx}.png\"), np.hstack([image_vis, gt_mask, pred_mask])[:,:,::-1])\n    \n    visualize(\n        original_image = image_vis,\n        ground_truth_mask = gt_mask,\n        predicted_mask = pred_mask,\n        pred_polyp_heatmap = pred_polyp_heatmap\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:16:22.901033Z","iopub.execute_input":"2022-06-24T07:16:22.901784Z","iopub.status.idle":"2022-06-24T07:17:00.336604Z","shell.execute_reply.started":"2022-06-24T07:16:22.901532Z","shell.execute_reply":"2022-06-24T07:17:00.335718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_epoch = smp.utils.train.ValidEpoch(\n    model,\n    loss=smp.utils.losses.DiceLoss(), \n    metrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n], \n    device=DEVICE,\n    verbose=True,\n)\n\nvalid_logs = test_epoch.run(test_dataloader)\nprint(\"Evaluation on Test Data: \")\nprint(f\"Mean IoU Score: {valid_logs['iou_score']:.4f}\")\nprint(f\"Mean Dice Loss: {valid_logs['dice_loss']:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T07:17:00.337943Z","iopub.execute_input":"2022-06-24T07:17:00.338422Z","iopub.status.idle":"2022-06-24T07:17:05.676442Z","shell.execute_reply.started":"2022-06-24T07:17:00.338376Z","shell.execute_reply":"2022-06-24T07:17:05.675405Z"},"trusted":true},"execution_count":null,"outputs":[]}]}